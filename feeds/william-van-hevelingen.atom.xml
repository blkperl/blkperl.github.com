<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>puppet resource blog author=blkperl</title><link href="http://blkperl.github.com/" rel="alternate"></link><link href="http://blkperl.github.com/feeds/william-van-hevelingen.atom.xml" rel="self"></link><id>http://blkperl.github.com/</id><updated>2014-04-17T00:13:00-07:00</updated><entry><title>Building DevOps Dashboards with Puppet</title><link href="http://blkperl.github.com/building_devops_dashboards_with_puppet.html" rel="alternate"></link><updated>2014-04-17T00:13:00-07:00</updated><author><name>William Van Hevelingen</name></author><id>tag:blkperl.github.com,2014-04-17:building_devops_dashboards_with_puppet.html</id><summary type="html">&lt;p&gt;Graphite is awesome. The variety of metrics that you can put in it and the ability to build graphs to visualize specific things is an invaluable tool. However, most of the time, I just want to be able to do a quick glance at a few key things on a server like CPU usage, memory usage, disk I/O, and network traffic. While it's easy to bring these graphs up individually, in the default Graphite web UI, it's a bit harder to flip through several different server metrics quickly. Not to mention getting them in the particular way you want to view them.&lt;/p&gt;
&lt;p&gt;At this point, you want to build a DevOps dashboard and there's a ton of choices to choose from that goes way beyond the capabilities of the default Graphite web UI. Although, you still end up with the problem of building a dashboard for each host and I have 200+ nodes. Sure, I could write a script to do it but why repeat myself when Puppet could do this for me.&lt;/p&gt;
&lt;p&gt;I just needed to find a Graphite dashboard that I could easily model in Puppet via config files. Originally, I looked at Gdash by @ripienaar. It implements a simple DSL for Graphite that I could have easily modeled in Puppet templates but I just so happened upon the following tweet.&lt;/p&gt;
&lt;blockquote class="twitter-tweet" lang="en"&gt;&lt;p&gt;New GDash inspired dashboard for Graphite &lt;a href="http://t.co/8AJEZX1Jvl"&gt;http://t.co/8AJEZX1Jvl&lt;/a&gt; from &lt;a href="https://twitter.com/juliendehee"&gt;@juliendehee&lt;/a&gt;&lt;/p&gt;&amp;mdash; R.I.Pienaar (@ripienaar) &lt;a href="https://twitter.com/ripienaar/statuses/423934247750365184"&gt;January 16, 2014&lt;/a&gt;&lt;/blockquote&gt;

&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;@juliendehee's Leonardo dashboard for Graphite is a simple Python Flask app that hits the Graphite render API to generate graphs. Instead of a DSL language like GDash it uses YAML files. At this point, I was positive someone had already written a Puppet type for YAML. So, I went looking on the Puppet Forge and sure enough Reid had already done the work for me.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://forge.puppetlabs.com/reidmv/yamlfile"&gt;https://forge.puppetlabs.com/reidmv/yamlfile&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A few hours of hacking later and I had a Puppet module for Leonardo. It works exactly like the Nagios host/service pattern using exported resources.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Your Puppet Masters need to be using PuppetDB.&lt;/li&gt;
&lt;li&gt;You need to install a recent version of Puppet (&amp;gt;= 3.4.x) with Future parser enabled&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;To get started you need to add the leonardo module to your Puppet masters.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;puppet module install pdxcat-leonardo
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Or you can download it directly from &lt;a href="https://github.com/pdxcat/puppet-module-leonardo"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Leonardo server configuration&lt;/h2&gt;
&lt;p&gt;Next, you will want to install Leonardo on a webserver. Below, you can see my &lt;code&gt;role::leonardo&lt;/code&gt; puppet class. Include this class in your leonardo servers node definition. The leonardo class installs the packages needed for Leonardo, does some basic configuration and does a git clone of the source code from GitHub [1]. You can choose to omit the Leonardo class if you want to do it differently. Also since web server configuration is usually environment specific, I'm going to omit it from this blog post but here is an example for setting it up with Apache in the &lt;code&gt;test/init.pp&lt;/code&gt; file using the puppetlabs/apache module [2].&lt;/p&gt;
&lt;p&gt;The key lines to understand in this code snippet is the "mothership" operators also called exported resource collectors [3]. Lines 15-17 will collect all the leonardo resources that we are going to export on our target nodes. Then whenever the leonardo server checks in with Puppet it will ensure that all leonardo resources are created.&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/10956900.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;class role::leonardo {

  $template_dir = '/opt/leonardo/leonardo/graphs'

  class { '::leonardo':
    graphite_url =&gt; 'https://graphite.example.org',
    template_dir =&gt; $template_dir,
    install_dir  =&gt; '/opt/leonardo/leonardo',
  }-&gt;
  file { [$template_dir, "${template_dir}/servers"]:
    ensure =&gt; directory,
  }

  # Environment tag can be removed when environment support is added to PuppetDB
  File                &lt;&lt;| tag == "env_leonardo_${::environment}" |&gt;&gt; {}
  Leonardo::Dashboard &lt;&lt;| tag == "env_leonardo_${::environment}" |&gt;&gt; {}
  Leonardo::Graph     &lt;&lt;| tag == "env_leonardo_${::environment}" |&gt;&gt; {}
}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;h2&gt;Leonardo client configuration&lt;/h2&gt;
&lt;p&gt;For the target node configuration we need to export resources. The following code snippet contains an example of &lt;code&gt;role::leonardo::client&lt;/code&gt;. Include the &lt;code&gt;role::leonardo::client&lt;/code&gt; class on every node that you want a dashboard for.&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/9826382.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;class role::leonardo::client {

  $dashboard_root = '/opt/leonardo/graphs/servers',
  $collectd_name  = regsubst($::fqdn, '\.', '_', 'G'),
  $dashboard_dir  = "${dashboard_root}/${::hostname}",

  # Each dashboard needs a directory to hold the graph files
  @@file { $dashboard_dir:
    ensure =&gt; directory,
    mode   =&gt; '0755',
    tag    =&gt; "env_leonardo_${environment}",
  }

  # Each dashboard needs a a dash.yaml file
  @@leonardo::dashboard { $::hostname:
    target             =&gt; "${dashboard_dir}/dash.yaml",
    name               =&gt; $::hostname,
    description        =&gt; 'System Metrics',
    include_properties =&gt; ['common.yaml'],
    tag                =&gt; "env_leonardo_${environment}",
    require            =&gt; File[$dashboard_dir],
  }
  
  # Export a cpu graph
  @@leonardo::graph { "${::hostname}-cpu":
    target     =&gt; "${dashboard_dir}/10-cpu.graph",
    parameters =&gt; { 'title'  =&gt; 'Combined CPU Usage',
                    'vtitle' =&gt; 'percent',
                    'area'   =&gt; 'stacked' },
    fields     =&gt; {
                    'iowait' =&gt; { 'data' =&gt; "sumSeries(collectd.${collectd_name}.cpu*.cpu-wait)",},
                    'system' =&gt; { 'data' =&gt; "sumSeries(collectd.${collectd_name}.cpu*.cpu-system)",},
                    'user'   =&gt; { 'data' =&gt; "sumSeries(collectd.${collectd_name}.cpu*.cpu-user)",},
                  },
    tag       =&gt; "env_leonardo_${environment}",
    require   =&gt; File[$dashboard_dir],
  }

}&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;In this particular example, we are exporting a leonardo dashboard file, a directory for each server to hold the graphs, and a CPU graph. Check out the link at the bottom for our current list of graphs that we export on all nodes [4]. It should be a good starting point for getting the more common graphs up and running.&lt;/p&gt;
&lt;h2&gt;Graphs and Profit!&lt;/h2&gt;
&lt;p&gt;After running Puppet on both the target node and the Leonardo server, you should see a servers dropdown menu. Upon selecting a server from the list you should see something similar to the dashboard below.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Leonardo Dashboard" src="http://blkperl.github.com/images/leonardo_dashboard.png" /&gt;&lt;/p&gt;
&lt;p&gt;Once you're confident that you have the graphs you want defined in Puppet and have tested on one node. Include the leonardo client class on all your nodes and watch as it creates a dashboard for each server as Puppet nodes start to check in and Puppet runs on your Leonardo server.&lt;/p&gt;
&lt;h2&gt;Role Based Graphs&lt;/h2&gt;
&lt;p&gt;Now that we have a bunch of graphs that should be displayed for each node we can start adding ones for specific roles. Similar to the way you might export Nagios service checks depending on a Puppet class we can do the same with exporting leonardo dashboard resources.&lt;/p&gt;
&lt;p&gt;Let's say we have an OpenVPN role. Normally, we would have have our server configuration, monitoring, and environment specific code defined in this file so adding leonardo resources is a natural extension.&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/10961436.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;class role::vpnserver {

  class { 'openvpn::server':
     # environment specific parameters
  }

  class { 'collectd::plugin::openvpn':
    # environment specific parameters
  }

  @@leonardo::graph { "${::hostname}-openvpn":
    target     =&gt; "${dashboard_dir}/90-openvpn.graph",
    parameters =&gt; { 'title'    =&gt; 'OpenVPN connected users',
                    'vtitle'   =&gt; 'Users',
                    'linemode' =&gt; 'connected' },
    fields     =&gt; {
                    'users'   =&gt; { 'data' =&gt; "sumSeries(collectd.${collectd_name}.openvpn*.*)",},
                  },
    tag       =&gt; "env_leonardo_${environment}",
  }

}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;This ability is incredibly powerful because all that metadata that Puppet knows about your infrastructure via puppet classes is now available to help you build automated dashboards. You can take it a step further by exporting Graphs to role-based Dashboards. For example, a custom dashboard for an applications with graphs from the webservers, load balancers, and database servers.&lt;/p&gt;
&lt;h2&gt;Caveats&lt;/h2&gt;
&lt;p&gt;The current implement has a few issues that I'm going to gloss over in this post. Pull requests are welcome to help fix these problems.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Removing exported resources from PuppetDB is still a bit of a challenge&lt;/li&gt;
&lt;li&gt;Currently, old dashboards need to be manually removed as a purge parameter has not yet been implemented&lt;/li&gt;
&lt;li&gt;Yamlfile can be really slow on initial runs with a large number of hosts&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;TL;DR I used unreleased Puppet features to make shiny dashboards with very little effort thanks to Graphite, Collectd and Puppet.&lt;/p&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.puppetlabs.com/puppet/latest/reference/experiments_future.html"&gt;Puppet Future Parser&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.puppetlabs.com/puppetdb/latest/"&gt;PuppetDB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[1] At the time of writing there are no packages for Leonardo available&lt;/li&gt;
&lt;li&gt;[2] &lt;a href="https://github.com/pdxcat/puppet-module-leonardo/blob/master/tests/init.pp"&gt;Installing Leonardo with Apache example puppet manifest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3] &lt;a href="http://docs.puppetlabs.com/puppet/latest/reference/lang_exported.html#collecting-exported-resources"&gt;Docs on Exported resource collectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[4] &lt;a href="https://gist.github.com/blkperl/10958057"&gt;Full Leonardo client example&lt;/a&gt; (Note: this very much a work in progress)&lt;/li&gt;
&lt;/ul&gt;</summary><category term="puppet"></category><category term="graphite"></category><category term="leonardo"></category><category term="metrics"></category></entry><entry><title>Using Vagrant with Solaris 11</title><link href="http://blkperl.github.com/vagrant_solaris11.html" rel="alternate"></link><updated>2014-02-19T23:23:00-08:00</updated><author><name>William Van Hevelingen</name></author><id>tag:blkperl.github.com,2014-02-19:vagrant_solaris11.html</id><summary type="html">&lt;p&gt;I finally got Solaris 11 vagrant boxes working! &lt;/p&gt;
&lt;p&gt;First you need to download a Solaris 11 iso from Oracle's website. Then use packer to build a solaris11 box file which is explained in Alan Chalmer's &lt;a href="http://resilvered.blogspot.com/2014/02/solaris-vagrant-packer-and-base-box.html"&gt;blog&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Next we need a Vagrantfile, you can pull down mine and modify it for your needs. Then create an iso directory and place your solaris box image in it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git clone https://gist.github.com/9108604.git
mkdir iso
cp /packer/build/directory/packer_solaris-11.1-amd64_virtualbox.box iso/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our Vagrantfile looks like this. To mirror a production setup we are creating a secondary disk on the IDE controller to mirror rpool. Then we create a SATA controller and attach six 1G disks.&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/9108604.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;# -*- mode: ruby -*-
# vi: set ft=ruby :

# Vagrantfile API/syntax version. Don't touch unless you know what you're doing!
VAGRANTFILE_API_VERSION = "2"

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|

  diskroot = "/home/#{ENV['USER']}/VirtualBox\ VMs/"

  config.vm.define "sunosfiler" do |v|
    v.vm.box = "solaris-11.1"
    v.vm.hostname = "sunosfiler"
    v.vm.network :private_network, ip: "192.168.2.13"
    v.vm.box_url = "iso/packer_solaris-11.1-amd64_virtualbox.box"
    v.vm.provider :virtualbox do |vb|
      # Create a sata controller for our disks
      vb.customize ["storagectl", :id, "--name", "SATA Controller", "--add", 'sata']
      # Create a second disk for the rpool mirror
      diskname = "#{diskroot}/sunosfiler-ide1.vdi"
      vb.customize ['createhd', '--filename', diskname, '--size', 8 * 1024]
      vb.customize ['storageattach', :id, '--storagectl', 'IDE Controller', '--port', 1, '--device', 0, '--type', 'hdd', '--medium', diskname]
    end
    # Create six disks for a zpool
    v.vm.provider :virtualbox do |vb|
      ["1","2","3","4","5","6"].each do |disk|
       diskname = "#{diskroot}/sunosfiler-sata#{disk}.vdi"
       vb.customize ['createhd', '--filename', diskname, '--size', 1024]
       vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', disk, '--device', 0, '--type', 'hdd', '--medium', diskname]
      end
    end
  end
end&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;Now that we have everything we need we can start the vm with vagrant up.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;vagrant up
Bringing machine &lt;span class="s1"&gt;&amp;#39;sunosfiler&amp;#39;&lt;/span&gt; up with &lt;span class="s1"&gt;&amp;#39;virtualbox&amp;#39;&lt;/span&gt; provider...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Box &lt;span class="s1"&gt;&amp;#39;solaris-11.1&amp;#39;&lt;/span&gt; was not found. Fetching box from specified URL &lt;span class="k"&gt;for&lt;/span&gt;
the provider &lt;span class="s1"&gt;&amp;#39;virtualbox&amp;#39;&lt;/span&gt;. Note that &lt;span class="k"&gt;if&lt;/span&gt; the URL does not have
a box &lt;span class="k"&gt;for&lt;/span&gt; this provider, you should interrupt Vagrant now and add
the box yourself. Otherwise Vagrant will attempt to download the
full box prior to discovering this error.
Downloading or copying the box...
Extracting box...te: 25.0M/s, Estimated &lt;span class="nb"&gt;time &lt;/span&gt;remaining: 0:00:01&lt;span class="o"&gt;)&lt;/span&gt;
Successfully added box &lt;span class="s1"&gt;&amp;#39;solaris-11.1&amp;#39;&lt;/span&gt; with provider &lt;span class="s1"&gt;&amp;#39;virtualbox&amp;#39;&lt;/span&gt;!
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Importing base box &lt;span class="s1"&gt;&amp;#39;solaris-11.1&amp;#39;&lt;/span&gt;...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Matching MAC address &lt;span class="k"&gt;for&lt;/span&gt; NAT networking...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Setting the name of the VM...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Setting the name of the VM...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Clearing any previously &lt;span class="nb"&gt;set &lt;/span&gt;forwarded ports...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Creating shared folders metadata...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Clearing any previously &lt;span class="nb"&gt;set &lt;/span&gt;network interfaces...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Preparing network interfaces based on configuration...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Forwarding ports...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; -- &lt;span class="nv"&gt;22&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; &lt;span class="m"&gt;2222&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;adapter 1&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Running any VM customizations...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Booting VM...
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Waiting &lt;span class="k"&gt;for&lt;/span&gt; VM to boot. This can take a few minutes.
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; VM booted and ready &lt;span class="k"&gt;for&lt;/span&gt; use!
&lt;span class="o"&gt;[&lt;/span&gt;sunosfiler&lt;span class="o"&gt;]&lt;/span&gt; Setting hostname...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we login and become the root user.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;vagrant ssh
sudo -i
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next let's take a look at the disks that we attached. You can use the format command to list the availible disks.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;format
Searching &lt;span class="k"&gt;for&lt;/span&gt; disks...done


AVAILABLE DISK SELECTIONS:
       0. c7d0 &amp;lt;VBOX HAR-bafb5063-0735aa9-0001-8.00GB&amp;gt;
          /pci@0,0/pci-ide@1,1/ide@0/cmdk@0,0
       1. c8d0 &amp;lt;VBOX HAR-196ca772-16ab95f-0001 cyl &lt;span class="m"&gt;4093&lt;/span&gt; alt &lt;span class="m"&gt;2&lt;/span&gt; hd &lt;span class="m"&gt;128&lt;/span&gt; sec 32&amp;gt;
          /pci@0,0/pci-ide@1,1/ide@1/cmdk@0,0
       2. c9t1d0 &amp;lt;ATA-VBOX HARDDISK-1.0 cyl &lt;span class="m"&gt;1022&lt;/span&gt; alt &lt;span class="m"&gt;2&lt;/span&gt; hd &lt;span class="m"&gt;64&lt;/span&gt; sec 32&amp;gt;
          /pci@0,0/pci8086,2829@d/disk@1,0
       3. c9t2d0 &amp;lt;ATA-VBOX HARDDISK-1.0 cyl &lt;span class="m"&gt;1022&lt;/span&gt; alt &lt;span class="m"&gt;2&lt;/span&gt; hd &lt;span class="m"&gt;64&lt;/span&gt; sec 32&amp;gt;
          /pci@0,0/pci8086,2829@d/disk@2,0
       4. c9t3d0 &amp;lt;ATA-VBOX HARDDISK-1.0 cyl &lt;span class="m"&gt;1022&lt;/span&gt; alt &lt;span class="m"&gt;2&lt;/span&gt; hd &lt;span class="m"&gt;64&lt;/span&gt; sec 32&amp;gt;
          /pci@0,0/pci8086,2829@d/disk@3,0
       5. c9t4d0 &amp;lt;ATA-VBOX HARDDISK-1.0 cyl &lt;span class="m"&gt;1022&lt;/span&gt; alt &lt;span class="m"&gt;2&lt;/span&gt; hd &lt;span class="m"&gt;64&lt;/span&gt; sec 32&amp;gt;
          /pci@0,0/pci8086,2829@d/disk@4,0
       6. c9t5d0 &amp;lt;ATA-VBOX HARDDISK-1.0 cyl &lt;span class="m"&gt;1022&lt;/span&gt; alt &lt;span class="m"&gt;2&lt;/span&gt; hd &lt;span class="m"&gt;64&lt;/span&gt; sec 32&amp;gt;
          /pci@0,0/pci8086,2829@d/disk@5,0
       7. c9t6d0 &amp;lt;ATA-VBOX HARDDISK-1.0 cyl &lt;span class="m"&gt;1022&lt;/span&gt; alt &lt;span class="m"&gt;2&lt;/span&gt; hd &lt;span class="m"&gt;64&lt;/span&gt; sec 32&amp;gt;
          /pci@0,0/pci8086,2829@d/disk@6,0
Specify disk &lt;span class="o"&gt;(&lt;/span&gt;enter its number&lt;span class="o"&gt;)&lt;/span&gt;:
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can see that c7d0 and c8d0 are our 8G system disks attached to the IDE controller. Let's attach c8d0 to the rpool and make a mirror.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;zpool attach rpool c7d0 c8d0
Make sure to &lt;span class="nb"&gt;wait &lt;/span&gt;&lt;span class="k"&gt;until&lt;/span&gt; resilver is &lt;span class="k"&gt;done&lt;/span&gt; before rebooting.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If we examine the pool now, we can see it resilvering.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;zpool&lt;/span&gt; &lt;span class="nx"&gt;status&lt;/span&gt; &lt;span class="nx"&gt;rpool&lt;/span&gt;
  &lt;span class="nx"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;rpool&lt;/span&gt;
 &lt;span class="nx"&gt;state&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;DEGRADED&lt;/span&gt;
&lt;span class="nx"&gt;status&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;One&lt;/span&gt; &lt;span class="nx"&gt;or&lt;/span&gt; &lt;span class="nx"&gt;more&lt;/span&gt; &lt;span class="nx"&gt;devices&lt;/span&gt; &lt;span class="nx"&gt;is&lt;/span&gt; &lt;span class="nx"&gt;currently&lt;/span&gt; &lt;span class="nx"&gt;being&lt;/span&gt; &lt;span class="nx"&gt;resilvered&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;  &lt;span class="nx"&gt;The&lt;/span&gt; &lt;span class="nx"&gt;pool&lt;/span&gt; &lt;span class="nx"&gt;will&lt;/span&gt;
        &lt;span class="k"&gt;continue&lt;/span&gt; &lt;span class="nx"&gt;to&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;a&lt;/span&gt; &lt;span class="nx"&gt;degraded&lt;/span&gt; &lt;span class="nx"&gt;state&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="nx"&gt;action&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Wait&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;the&lt;/span&gt; &lt;span class="nx"&gt;resilver&lt;/span&gt; &lt;span class="nx"&gt;to&lt;/span&gt; &lt;span class="nx"&gt;complete&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
        &lt;span class="nx"&gt;Run&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;zpool status -v&amp;#39;&lt;/span&gt; &lt;span class="nx"&gt;to&lt;/span&gt; &lt;span class="nx"&gt;see&lt;/span&gt; &lt;span class="nx"&gt;device&lt;/span&gt; &lt;span class="nx"&gt;specific&lt;/span&gt; &lt;span class="nx"&gt;details&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
  &lt;span class="nx"&gt;scan&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;resilver&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;progress&lt;/span&gt; &lt;span class="nx"&gt;since&lt;/span&gt; &lt;span class="nx"&gt;Thu&lt;/span&gt; &lt;span class="nx"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;2014&lt;/span&gt;
    &lt;span class="mi"&gt;809&lt;/span&gt;&lt;span class="nx"&gt;M&lt;/span&gt; &lt;span class="nx"&gt;scanned&lt;/span&gt; &lt;span class="nx"&gt;out&lt;/span&gt; &lt;span class="nx"&gt;of&lt;/span&gt; &lt;span class="mf"&gt;3.69&lt;/span&gt;&lt;span class="nx"&gt;G&lt;/span&gt; &lt;span class="nx"&gt;at&lt;/span&gt; &lt;span class="mf"&gt;38.5&lt;/span&gt;&lt;span class="nx"&gt;M&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="nx"&gt;h1m&lt;/span&gt; &lt;span class="nx"&gt;to&lt;/span&gt; &lt;span class="nx"&gt;go&lt;/span&gt;
    &lt;span class="mi"&gt;777&lt;/span&gt;&lt;span class="nx"&gt;M&lt;/span&gt; &lt;span class="nx"&gt;resilvered&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;21.40&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nx"&gt;done&lt;/span&gt;
&lt;span class="nx"&gt;config&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;

        &lt;span class="nx"&gt;NAME&lt;/span&gt;        &lt;span class="nx"&gt;STATE&lt;/span&gt;     &lt;span class="nx"&gt;READ&lt;/span&gt; &lt;span class="nx"&gt;WRITE&lt;/span&gt; &lt;span class="nx"&gt;CKSUM&lt;/span&gt;
        &lt;span class="nx"&gt;rpool&lt;/span&gt;       &lt;span class="nx"&gt;DEGRADED&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
          &lt;span class="nx"&gt;mirror&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="nx"&gt;DEGRADED&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="nx"&gt;c7d0&lt;/span&gt;    &lt;span class="nx"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="nx"&gt;c8d0&lt;/span&gt;    &lt;span class="nx"&gt;DEGRADED&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;resilvering&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nx"&gt;errors&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;No&lt;/span&gt; &lt;span class="nx"&gt;known&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt; &lt;span class="nx"&gt;errors&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After a few minutes it should be fully online. Then we need to install grub on the new disk&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;bootadm install-bootloader -P rpool
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that our root pool is setup we can move on to our storage pool. I choose to mirror every disk but you can choose whatever raid configuration you prefer.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;zpool create stark mirror c9t1d0 c9t2d0 mirror c9t3d0 c9t4d0 mirror c9t5d0 c9t6d0
zpool status stark
  pool: stark
 state: ONLINE
  scan: none requested
config:

        NAME        STATE     READ WRITE CKSUM
        stark       ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0
          mirror-0  ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0
            c9t1d0  ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0
            c9t2d0  ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0
          mirror-1  ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0
            c9t3d0  ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0
            c9t4d0  ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0
          mirror-2  ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0
            c9t5d0  ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0
            c9t6d0  ONLINE       &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     0

errors: No known data errors
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point our storage is configured and we can move on to creating filesystems, setting up services, or running tests.&lt;/p&gt;
&lt;p&gt;Happy Hacking!&lt;/p&gt;</summary><category term="solaris"></category><category term="vagrant"></category></entry><entry><title>Creating a Puppet development environment with LXC</title><link href="http://blkperl.github.com/puppet-dev-with-lxc.html" rel="alternate"></link><updated>2013-05-26T16:00:00-07:00</updated><author><name>William Van Hevelingen</name></author><id>tag:blkperl.github.com,2013-05-26:puppet-dev-with-lxc.html</id><summary type="html">&lt;p&gt;This blog post is about my development setup on my laptop for testing out new software. You will learn how you can easily create LXC containers and connect them to a puppet master in about 20 minutes using the awesome cloning features of LXC.&lt;/p&gt;
&lt;p&gt;LXC is a lightweight container virtualization technology very similar to Solaris zones and FreeBSD jails and is availible on most Linux distributions. To learn more and read the docs check out the links at the bottom of the post. &lt;/p&gt;
&lt;p&gt;The first step is to install it.&lt;/p&gt;
&lt;h2&gt;Install LXC&lt;/h2&gt;
&lt;p&gt;On Ubuntu installing LXC is easy and the package comes with working Ubuntu and Debian templates.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo apt-get install lxc
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Create a puppet master&lt;/h2&gt;
&lt;p&gt;The first thing we need is a puppet master. To do this we are going to use the lxc-create command to create a minimal Ubuntu Precise instance.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Create a fresh precise minimal install&lt;/span&gt;
lxc-create -n pdxpuppet-master -t ubuntu -- --release&lt;span class="o"&gt;=&lt;/span&gt;precise

&lt;span class="c"&gt;# Start your puppet master&lt;/span&gt;
lxc-start -n pdxpuppet-master -d

&lt;span class="c"&gt;# Determine the ip address&lt;/span&gt;
lxc-ls --fancy

&lt;span class="c"&gt;# Log in with the default username: ubuntu and password: ubuntu&lt;/span&gt;
ssh ubuntu@10.0.3.118
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You may need to wait a few seconds for the container to start before the ip address will be displayed in the output of lxc-ls --fancy&lt;/p&gt;
&lt;h2&gt;Configure your puppet master&lt;/h2&gt;
&lt;p&gt;Now we need to configure our new instance to be a puppet master.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Become the root user&lt;/span&gt;
sudo -i

&lt;span class="c"&gt;# Install wget&lt;/span&gt;
apt-get install wget

&lt;span class="c"&gt;# Install the puppetlabs apt repository&lt;/span&gt;
wget http://apt.puppetlabs.com/puppetlabs-release-precise.deb
dpkg -i puppetlabs-release-precise.deb
apt-get update

&lt;span class="c"&gt;# Install the webrick puppetmaster&lt;/span&gt;
apt-get install puppet puppetmaster
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The webrick puppetmaster is not recommended for production use. At this point you can choose to configure Apache and &lt;a href="http://docs.puppetlabs.com/guides/passenger.html"&gt;Passenger&lt;/a&gt; or an alternative.&lt;/p&gt;
&lt;h2&gt;Create a puppet client&lt;/h2&gt;
&lt;p&gt;Next we need a puppet client. The process will be almost identical to creating our puppet master.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Create a fresh precise minimal install&lt;/span&gt;
lxc-create -n pdxpuppet-client0 -t ubuntu -- --release&lt;span class="o"&gt;=&lt;/span&gt;precise

&lt;span class="c"&gt;# Start your puppet client0&lt;/span&gt;
lxc-start -n pdxpuppet-client0 -d

&lt;span class="c"&gt;# Determine the ip address&lt;/span&gt;
lxc-ls --fancy

&lt;span class="c"&gt;# Log in with the default username: ubuntu and password: ubuntu&lt;/span&gt;
ssh ubuntu@10.0.3.119
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Configure the client&lt;/h2&gt;
&lt;p&gt;Next we need to configure our client to know about the puppet master.&lt;/p&gt;
&lt;p&gt;Replace 10.0.3.118 with the ip of your puppetmaster&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Become the root user&lt;/span&gt;
sudo -i

&lt;span class="c"&gt;# In this environment we don&amp;#39;t have DNS so add the puppet master to /etc/hosts&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;10.0.3.118 puppet puppet.lan&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /etc/hosts

&lt;span class="c"&gt;# Install puppet&lt;/span&gt;
apt-get install puppet

&lt;span class="c"&gt;# Make puppet start on boot&lt;/span&gt;
/bin/sed -i &lt;span class="s1"&gt;&amp;#39;s/START\=no/START\=yes/&amp;#39;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/etc/default/puppet&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this stage you can add any other useful tools or configuration. I usually install vim, git and ssh keys for root login from my laptop.&lt;/p&gt;
&lt;p&gt;After you're finished configuring the client turn it off.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;lxc-stop -n pdxpuppet-client0
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Configure Puppet Autosigning on your master&lt;/h2&gt;
&lt;p&gt;This next step is for convenience. If you want to avoid signing certs in your development environment you can turn on auto signing.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# On your puppetmaster&lt;/span&gt;

&lt;span class="c"&gt;# Allow hosts with domain name lan&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;*.lan&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /etc/puppet/autosign.conf

&lt;span class="c"&gt;# Restart the puppet master&lt;/span&gt;
service puppetmaster restart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Auto signing is described in the docs &lt;a href="http://docs.puppetlabs.com/guides/configuring.html#autosignconf"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There are security concerns with auto signing as described in the docs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;quot;As any host can provide any certname, autosigning should only be used with great care, and only in situations where you essentially trust any computer able to connect to the puppet master.&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this case my LXC environment is only on my laptop so I'm choosing to enable autosigining.&lt;/p&gt;
&lt;h2&gt;Add a node definition to your site.pp&lt;/h2&gt;
&lt;p&gt;Now we need to make a node definition for our client. By using a regex we can allow client 0 through client 9 to connect.&lt;/p&gt;
&lt;p&gt;On your puppet master add the following to /etc/puppet/manifests/site.pp&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;node&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="na"&gt;pdxpuppet&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="na"&gt;client&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c"&gt;&lt;/span&gt;

&lt;span class="c"&gt;  # add code here&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Clone more clients using client0&lt;/h2&gt;
&lt;p&gt;Now we X more clients. For now we will create 5 more.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# LXC will make an exact copy and tweak the network configs&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; i in &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt; 5&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; lxc-clone -o pdxpuppet-client0 -n pdxpuppet-client&lt;span class="nv"&gt;$i&lt;/span&gt; &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;done&lt;/span&gt;

&lt;span class="c"&gt;# Start your new machines&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; i in &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt; 5&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; lxc-start -n pdxpuppet-client&lt;span class="nv"&gt;$i&lt;/span&gt; &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After you're clients boot they should automatically check in with the puppetmaster and request certs.&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;At this point you have successfully configured a puppet master and five puppet clients that are ready for testing out new code. If you need more clients you can clone pdxpuppet-client0 and generate as many as you need and they will automatically connect to the puppet master on boot.&lt;/p&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/LXC"&gt;http://en.wikipedia.org/wiki/LXC&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://lxc.sourceforge.net/"&gt;http://lxc.sourceforge.net/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://help.ubuntu.com/12.04/serverguide/lxc.html"&gt;https://help.ubuntu.com/12.04/serverguide/lxc.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="lxc"></category><category term="puppet"></category></entry><entry><title>Fixing a split brain Ganeti instance</title><link href="http://blkperl.github.com/split-brain-ganeti.html" rel="alternate"></link><updated>2013-05-24T23:08:00-07:00</updated><author><name>William Van Hevelingen</name></author><id>tag:blkperl.github.com,2013-05-24:split-brain-ganeti.html</id><summary type="html">&lt;h2&gt;Recovering from split brain&lt;/h2&gt;
&lt;p&gt;We run a 4 node Ganeti cluster and during a failover of a node some instances got degraded disks. We're not sure how it happened but some quick googling told us it was a split brain and is recoverable. The following is how we confirmed it was split brain and how we repaired the affected instances.&lt;/p&gt;
&lt;h2&gt;You can identify a split brain by the following.&lt;/h2&gt;
&lt;p&gt;Degraded disks in gnt-instance info&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;on primary:   /dev/drbd1 &lt;span class="o"&gt;(&lt;/span&gt;147:1&lt;span class="o"&gt;)&lt;/span&gt; in sync, status *DEGRADED*
on secondary: /dev/drbd9 &lt;span class="o"&gt;(&lt;/span&gt;147:9&lt;span class="o"&gt;)&lt;/span&gt; in sync, status *DEGRADED*
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;StandAlone state on the primary (/proc/drbd)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 1: cs:StandAlone ro:Primary/Unknown ds:UpToDate/DUnknown   r-----
    ns:969536 nr:0 dw:22564060 dr:43036016 al:242 bm:2652 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:254024
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;StandAlone state on the secondary (/proc/drbd)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;9: cs:StandAlone ro:Primary/Unknown ds:UpToDate/DUnknown   r-----
    ns:0 nr:969536 dw:24185104 dr:996 al:0 bm:1293 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Steps to repair&lt;/h1&gt;
&lt;h2&gt;Recreate the secondary&lt;/h2&gt;
&lt;p&gt;(assuming you think the primary is healthy)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# replace $another_node with any node that is not the primary or secondary&lt;/span&gt;
gnt-instance replace-disks -n &lt;span class="nv"&gt;$another_node&lt;/span&gt; &lt;span class="nv"&gt;$instance&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Wait for disks to re-sync&lt;/h2&gt;
&lt;p&gt;You can watch the progress by looking at /proc/drbd&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1: cs:SyncSource ro:Primary/Secondary ds:UpToDate/Inconsistent C r-----
    ns:16437312 nr:0 dw:22602340 dr:59475304 al:256 bm:3653 lo:1 pe:123 ua:64 ap:0 ep:1 wo:f oos:4555336
        &lt;span class="o"&gt;[==============&lt;/span&gt;&amp;gt;.....&lt;span class="o"&gt;]&lt;/span&gt; synced: 78.3% &lt;span class="o"&gt;(&lt;/span&gt;4448/20480&lt;span class="o"&gt;)&lt;/span&gt;Mfinish: 0:01:14 speed: 61,144 &lt;span class="o"&gt;(&lt;/span&gt;58,212&lt;span class="o"&gt;)&lt;/span&gt; K/sec
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Verify the disks now&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gnt-instance info &lt;span class="nv"&gt;$instance&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; grep drbd
  Disk template: drbd
    - disk/0: drbd8, size 20.0G
      on primary:   /dev/drbd1 &lt;span class="o"&gt;(&lt;/span&gt;147:1&lt;span class="o"&gt;)&lt;/span&gt; in sync, status ok
      on secondary: /dev/drbd1 &lt;span class="o"&gt;(&lt;/span&gt;147:1&lt;span class="o"&gt;)&lt;/span&gt; in sync, status ok
&lt;/pre&gt;&lt;/div&gt;</summary><category term="ganeti"></category><category term="kvm"></category><category term="drbd"></category></entry><entry><title>Installing Sunray Software Server (SRSS) on Centos 5.x</title><link href="http://blkperl.github.com/centos_sunray.html" rel="alternate"></link><updated>2013-05-18T21:35:00-07:00</updated><author><name>William Van Hevelingen</name></author><id>tag:blkperl.github.com,2013-05-18:centos_sunray.html</id><summary type="html">&lt;p&gt;These are the steps I took to get the SunRay software working on Centos. I was able to get this working thanks to scraps of information from &lt;a href="http://blog.parahard.com/2009/06/installing-sunray-ii- erver-software-on.html"&gt;Peter Senna Tschudin's blog&lt;/a&gt; In addition to get it working on 32bit like in Peter's blog, I also got it working on 64 bit. These are the instructions for 64bit.&lt;/p&gt;
&lt;p&gt;The SunRays we have are the SunRay 2 model updated with the latest firmware.&lt;/p&gt;
&lt;h2&gt;Download the software from Oracle's support portal (requires login)&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; /opt/
&lt;span class="c"&gt;# download files from Oracle&amp;#39;s website&lt;/span&gt;
unzip V37034-01.zip
unzip p16406547_111_Generic.zip
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Install the dependencies&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;yum install glib dhcp openldap-clients tftp-server libXp libXfont.i386 openmotif22 openssl compat-libstdc++-33 libusb-devel compat-openldap kernel-devel gdbm.i386 gcc openmotif.i386 sssd-client.i386
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you are not using sssd you will need to install the nscd.i386 package.&lt;/p&gt;
&lt;h2&gt;Install the firmware&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; /opt/sros_11.1.1.0/
./utfwinstall 
Installing Sun Ray Operating Software 11.1.1.0

Sun Ray Operating Software 11.1.1.0 has been successfully installed.

This output has been logged to

    /var/log/utfwinstall.2013_05_09_14:48:54.log

+++ Done.
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Install the bundled JRE and Apache Tomcat&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; /opt/srs_5.4.0.0-Linux.i386/Supplemental/Java_Runtime_Environment/Linux
sh jre-6u41-linux-i586.bin 
mv jre1.6.0_41/ /opt/
&lt;span class="nb"&gt;cd&lt;/span&gt; /opt/srs_5.4.0.0-Linux.i386/Supplemental/Apache_Tomcat
gunzip apache-tomcat-5.5.36.tar.gz
tar xvf apache-tomcat-5.5.36.tar 
mv apache-tomcat-5.5.36 /opt/
ln -s /opt/apache-tomcat-5.5.36/ /opt/apache-tomcat
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Install the Sunray Server Software&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; /opt/srs_5.4.0.0-Linux.i386
./utsetup

&lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;
Accept? &lt;span class="o"&gt;(&lt;/span&gt;Y/N&lt;span class="o"&gt;)&lt;/span&gt; y
&lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;
Enter Java v1.6 &lt;span class="o"&gt;(&lt;/span&gt;or later&lt;span class="o"&gt;)&lt;/span&gt; location: &lt;span class="o"&gt;[&lt;/span&gt;/usr/java&lt;span class="o"&gt;]&lt;/span&gt; /opt/jre1.6.0_41/
&lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;
Continue? &lt;span class="o"&gt;(&lt;/span&gt;Y/N&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Y&lt;span class="o"&gt;]&lt;/span&gt; y

Enter new UT admin password:  
Again: Enter new UT admin password:  
Configure Sun Ray Web Administration? &lt;span class="o"&gt;(&lt;/span&gt;Y/N&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;N&lt;span class="o"&gt;]&lt;/span&gt; y

Enter Apache Tomcat installation directory &lt;span class="o"&gt;[&lt;/span&gt;/opt/apache-tomcat&lt;span class="o"&gt;]&lt;/span&gt;

Enter HTTP port number &lt;span class="o"&gt;[&lt;/span&gt;1660&lt;span class="o"&gt;]&lt;/span&gt; 8080

Enable secure connections? &lt;span class="o"&gt;(&lt;/span&gt;Y/N&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Y&lt;span class="o"&gt;]&lt;/span&gt; y

Enter HTTPS port number &lt;span class="o"&gt;[&lt;/span&gt;1661&lt;span class="o"&gt;]&lt;/span&gt; 8081

Enter Tomcat process username &lt;span class="o"&gt;[&lt;/span&gt;utwww&lt;span class="o"&gt;]&lt;/span&gt;

Enable remote server administration? &lt;span class="o"&gt;(&lt;/span&gt;Y/N&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;N&lt;span class="o"&gt;]&lt;/span&gt; Y

Configure Sun Ray Kiosk Mode? &lt;span class="o"&gt;(&lt;/span&gt;Y/N&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;N&lt;span class="o"&gt;]&lt;/span&gt; N

Configure this server &lt;span class="k"&gt;for&lt;/span&gt; a failover group? &lt;span class="o"&gt;(&lt;/span&gt;Y/N&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;N&lt;span class="o"&gt;]&lt;/span&gt;

About to configure the following software products:

Sun Ray Data Store 3.5
    Hostname: mysunrayserver.example.org
    Sun Ray root entry: &lt;span class="nv"&gt;o&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;utdata
    Sun Ray root name: utdata
    Sun Ray utdata admin password: &lt;span class="o"&gt;(&lt;/span&gt;not shown&lt;span class="o"&gt;)&lt;/span&gt;
    SRDS &lt;span class="s1"&gt;&amp;#39;rootdn&amp;#39;&lt;/span&gt;: &lt;span class="nv"&gt;cn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;admin,o&lt;span class="o"&gt;=&lt;/span&gt;utdata

Sun Ray Web Administration hosted at Apache Tomcat/5.5.36
    Apache Tomcat installation directory: /opt/apache-tomcat
    HTTP port number: 8080
    HTTPS port number: 8081
    Tomcat process username: utwww
    Remote server administration: Enabled

Sun Ray Server Software 4.5
    Failover group: no
    Sun Ray Kiosk Mode: no
Continue? &lt;span class="o"&gt;(&lt;/span&gt;Y/N&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Y&lt;span class="o"&gt;]&lt;/span&gt;

Enter groupname &lt;span class="k"&gt;for&lt;/span&gt; Windows Connector &lt;span class="o"&gt;[&lt;/span&gt;utwc&lt;span class="o"&gt;]&lt;/span&gt;

Enter group ID &lt;span class="o"&gt;(&lt;/span&gt;gid&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; the group &lt;span class="o"&gt;[&lt;/span&gt;auto&lt;span class="o"&gt;]&lt;/span&gt;

Do you want to configure Firmware downloads &lt;span class="k"&gt;for&lt;/span&gt; Sun Ray clients? &lt;span class="o"&gt;(&lt;/span&gt;Y/N&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Y&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Reboot&lt;/h2&gt;
&lt;p&gt;Seriously you should reboot&lt;/p&gt;
&lt;h2&gt;If the services are not running on reboot&lt;/h2&gt;
&lt;p&gt;You can manually start them with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;/opt/SUNWut/sbin/utadm -L on
/opt/SUNWut/sbin/utstart
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;SunRay Web Administration&lt;/h2&gt;
&lt;p&gt;Log into &lt;a href="https://mysunrayserver.example.org:8081"&gt;https://mysunrayserver.example.org:8081&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With the user: admin and the password you specified in the installer.&lt;/p&gt;
&lt;p&gt;Note: Replace port 8081 with the port you selected in the installer if you did not select 8081.&lt;/p&gt;
&lt;p&gt;If you can't log in because the "data store is not responding" proceed to the debugging section.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click "Advanced"&lt;/li&gt;
&lt;li&gt;Check all the encryption buttons&lt;/li&gt;
&lt;li&gt;Switch soft to hard for client and server&lt;/li&gt;
&lt;li&gt;Following instruction to restart client&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Debugging&lt;/h2&gt;
&lt;p&gt;The following two log files were especially helpful in debugging problems.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;tail -f /var/opt/SUNWut/log/messages
tail -f /var/log/autholog
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Security&lt;/h2&gt;
&lt;p&gt;We have the SunRays in there own vlan and only the SunRay servers are allowed to communicate with them. You should also firewall the Web Admin ports in my case port 8080 and 8081.&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;I havn't had a lot of luck with a consistent installation using the instructions above. If it doesn't work the first time try uninstalling and resintalling the SunRay software. Also I was doing this with SELinux disabled and we already had working SunRays with Solaris 10 so I can't really comment on the dhcp configs or any special network acls we may have in place.&lt;/p&gt;</summary><category term="centos"></category><category term="sunray"></category><category term="oracle"></category><category term="rhel"></category><category term="redhat"></category></entry><entry><title>Removing a patch from Solaris 10</title><link href="http://blkperl.github.com/remove_solaris_patch.html" rel="alternate"></link><updated>2013-03-27T12:00:00-07:00</updated><author><name>William Van Hevelingen</name></author><id>tag:blkperl.github.com,2013-03-27:remove_solaris_patch.html</id><summary type="html">&lt;p&gt;In this example we removed a custom IDR patch provided by Oracle.&lt;/p&gt;
&lt;h2&gt;Check to see if the patch is installed&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;caerbannog# showrev -p &lt;span class="p"&gt;|&lt;/span&gt; grep 148363
Patch: IDR148363-26 Obsoletes:  Requires: 147441-26 Incompatibles: 147441-27 Packages: SUNWnfsckr, SUNWzfskr, SUNWzfsu, SUNWzfsr
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Remove the patch with patchrm&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;caerbannog# patchrm IDR148363-26
Validating patches...

Loading patches installed on the system...

Done!

Checking patches that you specified &lt;span class="k"&gt;for&lt;/span&gt; removal.

Done!

Approved patches will be removed in this order:

IDR148363-26
Preparing checklist &lt;span class="k"&gt;for&lt;/span&gt; non-global zone check...

Checking non-global zones...


This patch passes non-global zone check.
IDR148363-26


Summary &lt;span class="k"&gt;for&lt;/span&gt; zones:

Zone crisco

Rejected patches:
None.
tches that passed the dependency check:
None.


Removing patches from non-global zones

Removing patches from zone crisco
Removing patch IDR148363-26...
Done!

Checking installed patches...

Backing out patch IDR148363-26...

Patch IDR148363-26 has been backed out.


Removing patches from zone nt4

Removing patches from zone sfw

Removing patches from global zone
Removing patch IDR148363-26...

Checking installed patches...

Executing prebackout script...
Backing out patch IDR148363-26...

Executing postbackout script...
Patch IDR148363-26 has been backed out.

Done!
&lt;/pre&gt;&lt;/div&gt;</summary><category term="solaris"></category></entry><entry><title>Replacing a Puppet CA Cert</title><link href="http://blkperl.github.com/replace-puppet-ca.html" rel="alternate"></link><updated>2013-03-26T22:50:00-07:00</updated><author><name>William Van Hevelingen</name></author><id>tag:blkperl.github.com,2013-03-26:replace-puppet-ca.html</id><summary type="html">&lt;p&gt;This is more of a story than a tutorial and I make no claims that this is the "correct" way to replace a Puppet CA cert but this is how we did it.&lt;/p&gt;
&lt;p&gt;Our puppet ca cert was going to expire in about 18 hours so we set aside some time when no one else was working on other systems and madly searched the internet for tidbits of information to replace the cert.&lt;/p&gt;
&lt;p&gt;In our environment we have a Puppet CA Server, a puppetmaster, and puppetdb/dashboard server and about 200 nix clients.&lt;/p&gt;
&lt;h2&gt;Prep Work&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Stop all puppet agents.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If running the daemon, run &lt;code&gt;service puppet stop&lt;/code&gt; on all the clients&lt;/p&gt;
&lt;p&gt;If running by cron then disable all the puppet crons.&lt;/p&gt;
&lt;p&gt;This is not necessary but it will prevent the clients from spamming logs while you replace the certs. It may also prevent some clients from getting into a weird limbo state.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verify time is correct on all the puppetmasters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the servers are not in sync then the certs generated will not work. I would recommend using NTP if you're not already running it.&lt;/p&gt;
&lt;h2&gt;Generate a new CA Cert&lt;/h2&gt;
&lt;p&gt;On the puppet ca remove the expired cert.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;rm -rf /var/lib/puppet/ssl
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Add any alternate dns names to /etc/puppet/puppet.conf&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;dns_alt_names=puppetca,puppetca.cat.pdx.edu,zeratul.cat.pdx.edu,zeratul
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Review the puppet.conf docs for other CA settings you may want to set before moving on.&lt;/p&gt;
&lt;h2&gt;Generate a new cert for the CA&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;puppet cert --generate zeratul.cat.pdx.edu
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Verify the new ca.pem and ca cert look correct.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;openssl x509 -text -noout -in /var/lib/puppet/ssl/certs/ca.pem
openssl x509 -text -noout -in /var/lib/puppet/ssl/certs/zeratul.cat.pdx.edu.pem
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Specifically, the validity field should now be 5 years in the future. You can set the expiration date in puppet.conf before you generate the cert if you want a longer or shorter period.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;openssl x509 -text -noout -in /var/lib/puppet/ssl/certs/ca.pem &lt;span class="p"&gt;|&lt;/span&gt; grep -i validity -A 2
        Validity
            Not Before: Mar &lt;span class="m"&gt;25&lt;/span&gt; 03:20:40 &lt;span class="m"&gt;2013&lt;/span&gt; GMT
            Not After : Mar &lt;span class="m"&gt;25&lt;/span&gt; 03:20:40 &lt;span class="m"&gt;2018&lt;/span&gt; GMT
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Restart apache.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;service apache2 restart
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generate a new cert for each puppet master&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# request a new cert on the puppetmaster&lt;/span&gt;
puppet agent --test --dns_alt_names&lt;span class="o"&gt;=&lt;/span&gt;tassadar,tassadar.cat.pdx.edu,puppet,puppet.cat.pdx.edu

&lt;span class="c"&gt;# on the ca server sign the cert&lt;/span&gt;
puppet cert --allow-dns-alt-names sign tassadar.cat.pdx.edu

&lt;span class="c"&gt;# restart apache on the puppet master&lt;/span&gt;
service apache2 restart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point your puppet master if configured to be an agent of itself, should be able to run &lt;code&gt;puppet agent --test&lt;/code&gt; with no errors unless you are running puppetdb.&lt;/p&gt;
&lt;h2&gt;Generate a new cert for puppetdb&lt;/h2&gt;
&lt;p&gt;The &lt;a href="http://docs.puppetlabs.com/puppetdb/1.1/maintain_and_tune.html#redo-ssl-setup-after-changing-certificates"&gt;official docs&lt;/a&gt; did not work for us. We had to add some additional steps documented below and we filed a &lt;a href="https://projects.puppetlabs.com/issues/19904"&gt;bug&lt;/a&gt; to update the docs or fix the &lt;code&gt;puppetdb-ssl-setup&lt;/code&gt; command.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Remove the old puppetdb certs on the puppetdb server&lt;/span&gt;
rm -rf /etc/puppetdb/ssl

&lt;span class="c"&gt;# Generate new puppetdb certs&lt;/span&gt;
puppetdb-ssl-setup

&lt;span class="c"&gt;# restart the service&lt;/span&gt;
service puppetdb restart

&lt;span class="c"&gt;# verify it restarts by watching the log (it may take a few minutes)&lt;/span&gt;
tail -f /var/log/puppetdb/puppetdb.log
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point if you did everything correct, the puppetmaster should be able to checkin to itself as a client with no errors and be able to download a catalog.&lt;/p&gt;
&lt;h2&gt;Request a cert for dashboard&lt;/h2&gt;
&lt;p&gt;Excerpt from the &lt;a href="http://docs.puppetlabs.com/dashboard/manual/1.2/configuring.html"&gt;official docs&lt;/a&gt; for the 1.2 stable release of dashboard.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# on the dashboard server&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; /usr/share/puppet-dashboard
rake cert:request

&lt;span class="c"&gt;# on the ca server&lt;/span&gt;
puppet cert sign dashboard

&lt;span class="c"&gt;# restart apache on the dashboard server&lt;/span&gt;
service apache2 restart
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Generate new certs for all your clients&lt;/h2&gt;
&lt;p&gt;Note if any clients are offline during the process they will need a new cert generated and signed when they come back online.&lt;/p&gt;
&lt;p&gt;We used a bash for loop that looked something like this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cat alltheclients.txt &lt;span class="p"&gt;|&lt;/span&gt; xargs -P &lt;span class="m"&gt;10&lt;/span&gt; -n &lt;span class="m"&gt;1&lt;/span&gt; -I box ssh -4 box &lt;span class="s1"&gt;&amp;#39;rm -fr /var/lib/puppet/ssl &amp;amp;&amp;amp; puppet agent -t&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The key part in this bash one liner is removing &lt;code&gt;/var/lib/puppet/ssl&lt;/code&gt; and requesting a new cert.&lt;/p&gt;
&lt;p&gt;Then on the puppet ca server we signed the new certs&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# For each client sign the new cert&lt;/span&gt;
puppet cert sign client2.cat.pdx.edu
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Or you can use the &lt;code&gt;--all&lt;/code&gt; flag&lt;/p&gt;
&lt;p&gt;There are some security risks with doing this. Basically for the same reasons on why not to use autosign. Read Brice's &lt;a href="http://www.masterzen.fr/2010/11/14/puppet-ssl-explained/"&gt;blog&lt;/a&gt; for more information about Puppet and SSl.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;puppet cert sign --all
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;This was a really painful process and is poorly documented. A lot of the clients were left in a broken state and needed to be kicked because the original for loop failed (probably because we didn't turn off the agents first). About 3 hours after we begun we had most of the clients working again and we fixed some stragglers the next day.&lt;/p&gt;
&lt;p&gt;If someone has a better/easier process for doing this, please blog about it or submit a pull request to the &lt;a href="http://docs.puppetlabs.com/contribute.html#editing-the-documentation"&gt;official docs&lt;/a&gt;.&lt;/p&gt;</summary><category term="puppet"></category><category term="openssl"></category></entry><entry><title>Evacuating a Ganeti node for hardware diagnostics</title><link href="http://blkperl.github.com/evac-ganeti-node.html" rel="alternate"></link><updated>2013-03-23T12:00:00-07:00</updated><author><name>William Van Hevelingen</name></author><id>tag:blkperl.github.com,2013-03-23:evac-ganeti-node.html</id><summary type="html">&lt;p&gt;One of the nodes in our Ganeti cluster was hanging on lvs commands and some of the instances were hanging while they wait for IO. I decided to be proactive and live migrate all of the instances off the node in order to bring it down for some debugging.&lt;/p&gt;
&lt;p&gt;The following steps are how I brought the node offline with minimal downtime for production instances.&lt;/p&gt;
&lt;h2&gt;Overview of our cluster&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;4 nodes&lt;/li&gt;
&lt;li&gt;46 instances&lt;/li&gt;
&lt;li&gt;Ubuntu 12.04 LTS&lt;/li&gt;
&lt;li&gt;Ganeti version 2.5.2-1&lt;/li&gt;
&lt;li&gt;Kvm version 1.0&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Log into the master node&lt;/h2&gt;
&lt;p&gt;Log into the master ganeti node.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ssh nebula.cat.pdx.edu
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Migrate the primary instances off suspect node&lt;/h2&gt;
&lt;p&gt;Run the gnt-node migrate command, passing in the node to migrate off of&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo gnt-node migrate katana.cat.pdx.edu
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The output should look similar to this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;root@claymore:~# gnt-node migrate katana
Migrate instance&lt;span class="o"&gt;(&lt;/span&gt;s&lt;span class="o"&gt;)&lt;/span&gt; crystal.cat.pdx.edu, l1011.cat.pdx.edu,
marauder.cat.pdx.edu, nyan.cat.pdx.edu, panic.cat.pdx.edu,
receptacle.cat.pdx.edu, ruby.cat.pdx.edu, sapphire.cat.pdx.edu,
webd.cat.pdx.edu, yermom.cat.pdx.edu, zeratul.cat.pdx.edu?
y/&lt;span class="o"&gt;[&lt;/span&gt;n&lt;span class="o"&gt;]&lt;/span&gt;/?: y
Submitted &lt;span class="nb"&gt;jobs &lt;/span&gt;52820, 52821, 52822, 52823, 52824, 52825, 52826, 52827, 52828, 52829, 52830
&lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;
Waiting &lt;span class="k"&gt;for&lt;/span&gt; job &lt;span class="m"&gt;52825&lt;/span&gt; ...
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:33:52 &lt;span class="m"&gt;2013&lt;/span&gt; Migrating instance crystal.cat.pdx.edu
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:33:52 &lt;span class="m"&gt;2013&lt;/span&gt; * checking disk consistency between &lt;span class="nb"&gt;source &lt;/span&gt;and target
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:33:56 &lt;span class="m"&gt;2013&lt;/span&gt; * switching node claymore.cat.pdx.edu to secondary mode
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:33:56 &lt;span class="m"&gt;2013&lt;/span&gt; * changing into standalone mode
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:34:58 &lt;span class="m"&gt;2013&lt;/span&gt; * changing disks into dual-master mode
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:35:01 &lt;span class="m"&gt;2013&lt;/span&gt; * &lt;span class="nb"&gt;wait &lt;/span&gt;&lt;span class="k"&gt;until&lt;/span&gt; resync is &lt;span class="k"&gt;done&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:35:02 &lt;span class="m"&gt;2013&lt;/span&gt; * preparing claymore.cat.pdx.edu to accept the instance
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:35:03 &lt;span class="m"&gt;2013&lt;/span&gt; * migrating instance to claymore.cat.pdx.edu
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:35:24 &lt;span class="m"&gt;2013&lt;/span&gt; * switching node katana.cat.pdx.edu to secondary mode
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:35:26 &lt;span class="m"&gt;2013&lt;/span&gt; * &lt;span class="nb"&gt;wait &lt;/span&gt;&lt;span class="k"&gt;until&lt;/span&gt; resync is &lt;span class="k"&gt;done&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:35:27 &lt;span class="m"&gt;2013&lt;/span&gt; * changing into standalone mode
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:35:27 &lt;span class="m"&gt;2013&lt;/span&gt; * changing disks into single-master mode
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:35:28 &lt;span class="m"&gt;2013&lt;/span&gt; * &lt;span class="nb"&gt;wait &lt;/span&gt;&lt;span class="k"&gt;until&lt;/span&gt; resync is &lt;span class="k"&gt;done&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:35:28 &lt;span class="m"&gt;2013&lt;/span&gt; * &lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Some of my instances failed to migrate properly. This seems to be related to this &lt;a href="https://code.google.com/p/ganeti/issues/detail?id=297"&gt;bug&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 10:33:16 &lt;span class="m"&gt;2013&lt;/span&gt; Migration failed, aborting
&lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;
Job &lt;span class="m"&gt;52820&lt;/span&gt; has failed: Failure: &lt;span class="nb"&gt;command &lt;/span&gt;execution error:
Could not migrate instance sapphire.cat.pdx.edu: Failed to migrate instance: Too many &lt;span class="s1"&gt;&amp;#39;info migrate&amp;#39;&lt;/span&gt; broken answers
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Luckly these instances were not being used at the moment and I could use gnt-instance failover.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Warning! This will reboot the instance&lt;/span&gt;
sudo gnt-instance failover sapphire.cat.pdx.edu
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Evacuate secondaries using gnt-node&lt;/h2&gt;
&lt;p&gt;After the primaries have been migrated run the gnt-node evacuate command to move the secondaries.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo gnt-node evacuate --secondary-only node2.cat.pdx.edu
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;gnt-node evacuate failed with a timeout error.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo gnt-node evacuate --secondary-only katana
Relocate instance&lt;span class="o"&gt;(&lt;/span&gt;s&lt;span class="o"&gt;)&lt;/span&gt; crystal.cat.pdx.edu, emerald.cat.pdx.edu,
&lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;
y/&lt;span class="o"&gt;[&lt;/span&gt;n&lt;span class="o"&gt;]&lt;/span&gt;/?: y
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 11:16:49 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Evacuating instances from node &lt;span class="s1"&gt;&amp;#39;katana.cat.pdx.edu&amp;#39;&lt;/span&gt;: crystal.cat.pdx.edu, emerald.cat.pdx.edu, fog.cat.pdx.edu, gameandwatch.cat.pdx.edu, l1011.cat.pdx.edu, log.cat.pdx.edu, marauder.cat.pdx.edu, nydus.cat.pdx.edu, panic.cat.pdx.edu, pika.cat.pdx.edu, receptacle.cat.pdx.edu, refinery.cat.pdx.edu, ruby.cat.pdx.edu, sapphire.cat.pdx.edu, void.cat.pdx.edu, warpgate.cat.pdx.edu, weba.cat.pdx.edu, webb.cat.pdx.edu, webc.cat.pdx.edu, webd.cat.pdx.edu, yermom.cat.pdx.edu, zeratul.cat.pdx.edu
Failure: &lt;span class="nb"&gt;command &lt;/span&gt;execution error:
Can&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;t get data &lt;span class="k"&gt;for&lt;/span&gt; node katana.cat.pdx.edu: Error 28: Operation timed out after &lt;span class="m"&gt;60910&lt;/span&gt; milliseconds with &lt;span class="m"&gt;0&lt;/span&gt; out of -1 bytes received
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If gnt-node evacuate fails for you can evacuate secondaries per instance.&lt;/p&gt;
&lt;h2&gt;Evacuate the secondaries using gnt-instance&lt;/h2&gt;
&lt;p&gt;Locate the instances you want to move.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo gnt-instance list -o name,pnode,snodes &lt;span class="p"&gt;|&lt;/span&gt; grep katana

gameandwatch.cat.pdx.edu claymore.cat.pdx.edu katana.cat.pdx.edu
l1011.cat.pdx.edu        rapier.cat.pdx.edu   katana.cat.pdx.edu
log.cat.pdx.edu          dirk.cat.pdx.edu     katana.cat.pdx.edu
marauder.cat.pdx.edu     rapier.cat.pdx.edu   katana.cat.pdx.edu
yermom.cat.pdx.edu       dirk.cat.pdx.edu     katana.cat.pdx.edu
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run gnt-instance replace-disks and give the name of another node that is not the primary of the instance.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo gnt-instance replace-disks -n claymore.cat.pdx.edu yermom.cat.pdx.edu
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The output will look similar to this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:39 &lt;span class="m"&gt;2013&lt;/span&gt; Replacing disk&lt;span class="o"&gt;(&lt;/span&gt;s&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; yermom.cat.pdx.edu
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:39 &lt;span class="m"&gt;2013&lt;/span&gt; STEP 1/6 Check device existence
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:39 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Checking disk/0 on rapier.cat.pdx.edu
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:40 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Checking volume groups
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:40 &lt;span class="m"&gt;2013&lt;/span&gt; STEP 2/6 Check peer consistency
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:40 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Checking disk/0 consistency on node rapier.cat.pdx.edu
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:40 &lt;span class="m"&gt;2013&lt;/span&gt; STEP 3/6 Allocate new storage
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:40 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Adding new &lt;span class="nb"&gt;local &lt;/span&gt;storage on claymore.cat.pdx.edu &lt;span class="k"&gt;for&lt;/span&gt; disk/0
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:44 &lt;span class="m"&gt;2013&lt;/span&gt; STEP 4/6 Changing drbd configuration
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:44 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: activating a new drbd on claymore.cat.pdx.edu &lt;span class="k"&gt;for&lt;/span&gt; disk/0
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:48 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Shutting down drbd &lt;span class="k"&gt;for&lt;/span&gt; disk/0 on old node
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:48 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Detaching primary drbds from the network &lt;span class="o"&gt;(=&lt;/span&gt;&amp;gt; standalone&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:49 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Updating instance configuration
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:49 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Attaching primary drbds to new secondary &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;standalone&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&amp;gt; connected&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:50 &lt;span class="m"&gt;2013&lt;/span&gt; STEP 5/6 Sync devices
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:50 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Waiting &lt;span class="k"&gt;for&lt;/span&gt; instance yermom.cat.pdx.edu to sync disks.
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:24:55 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0:  0.50% &lt;span class="k"&gt;done&lt;/span&gt;, 13m 34s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:26:00 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0:  6.90% &lt;span class="k"&gt;done&lt;/span&gt;, 15m 53s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:27:07 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 13.40% &lt;span class="k"&gt;done&lt;/span&gt;, 14m 42s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:28:26 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 21.00% &lt;span class="k"&gt;done&lt;/span&gt;, 13m 1s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:29:30 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 27.00% &lt;span class="k"&gt;done&lt;/span&gt;, 14m 32s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:30:35 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 33.20% &lt;span class="k"&gt;done&lt;/span&gt;, 11m 27s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:31:40 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 39.50% &lt;span class="k"&gt;done&lt;/span&gt;, 9m 56s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:32:44 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 45.80% &lt;span class="k"&gt;done&lt;/span&gt;, 9m 20s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:32:44 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 45.80% &lt;span class="k"&gt;done&lt;/span&gt;, 9m 20s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:33:49 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 52.10% &lt;span class="k"&gt;done&lt;/span&gt;, 8m 2s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:34:54 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 58.30% &lt;span class="k"&gt;done&lt;/span&gt;, 6m 54s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:35:58 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 64.60% &lt;span class="k"&gt;done&lt;/span&gt;, 5m 48s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:37:03 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 70.90% &lt;span class="k"&gt;done&lt;/span&gt;, 4m 52s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:38:08 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 77.20% &lt;span class="k"&gt;done&lt;/span&gt;, 3m 50s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:39:15 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 83.70% &lt;span class="k"&gt;done&lt;/span&gt;, 2m 33s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:40:20 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 90.00% &lt;span class="k"&gt;done&lt;/span&gt;, 1m 44s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:41:25 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: - device disk/0: 96.30% &lt;span class="k"&gt;done&lt;/span&gt;, 37s remaining &lt;span class="o"&gt;(&lt;/span&gt;estimated&lt;span class="o"&gt;)&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:42:04 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Instance yermom.cat.pdx.edu&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;s disks are in sync.
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:42:04 &lt;span class="m"&gt;2013&lt;/span&gt; STEP 6/6 Removing old storage
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:42:04 &lt;span class="m"&gt;2013&lt;/span&gt;  - INFO: Remove logical volumes &lt;span class="k"&gt;for&lt;/span&gt; 0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sometimes you may get an lvm error that looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:15:18 &lt;span class="m"&gt;2013&lt;/span&gt;  - WARNING: Can&lt;span class="s1"&gt;&amp;#39;t remove old LV: Can&amp;#39;&lt;/span&gt;t lvremove: exited with &lt;span class="nb"&gt;exit &lt;/span&gt;code &lt;span class="m"&gt;5&lt;/span&gt; -   Unable to deactivate open ganeti-9bc9b089--59f3-
-4512--9a09--e7f756caadbe.disk0_meta &lt;span class="o"&gt;(&lt;/span&gt;252:7&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;  Unable to deactivate logical volume &lt;span class="s2"&gt;&amp;quot;9bc9b089-59f3-4512-9a09-e7f756caadbe.disk0_meta&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;
Wed Mar &lt;span class="m"&gt;20&lt;/span&gt; 13:15:18 &lt;span class="m"&gt;2013&lt;/span&gt;       Hint: remove unused LVs manually
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If this happens you can manually remove the old volume with the lvremove command&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Log into the node&lt;/span&gt;
ssh katana.cat.pdx.edu
lvremove /dev/mapper/ganeti-9bc9b089-59f3-4512-9a09-e7f756caadbe.disk0_meta
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Mark the node offline&lt;/h2&gt;
&lt;p&gt;The last step is to mark the node offline&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo gnt-node modify -O yes katana.cat.pdx.edu
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;gnt-cluster verify should now display that one node is offline&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;gnt-cluster verify 
&lt;span class="o"&gt;[&lt;/span&gt;..&lt;span class="o"&gt;]&lt;/span&gt;
Sat Mar &lt;span class="m"&gt;23&lt;/span&gt; 14:18:14 &lt;span class="m"&gt;2013&lt;/span&gt; * Other Notes
Sat Mar &lt;span class="m"&gt;23&lt;/span&gt; 14:18:14 &lt;span class="m"&gt;2013&lt;/span&gt;   - NOTICE: &lt;span class="m"&gt;1&lt;/span&gt; offline node&lt;span class="o"&gt;(&lt;/span&gt;s&lt;span class="o"&gt;)&lt;/span&gt; found.
&lt;span class="o"&gt;[&lt;/span&gt;..&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And that is it, you can now take the node offline for diagnostics or to wait for new parts.&lt;/p&gt;
&lt;h2&gt;Rebalance the cluster&lt;/h2&gt;
&lt;p&gt;At this point you probably want to rebalance your Ganeti cluser. The following blog post by Lance Albertson does a pretty good job at explaining this process.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.lancealbertson.com/2011/05/rebalancing-ganeti-clusters/"&gt;http://www.lancealbertson.com/2011/05/rebalancing-ganeti-clusters/&lt;/a&gt;&lt;/p&gt;</summary><category term="ganeti"></category><category term="kvm"></category></entry></feed>